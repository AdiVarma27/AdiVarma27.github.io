{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Distributions + Intro to Bayesian Thinking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this post/ notebook, we take a look at how we can model real life problems with the use of basic probability distributions. This notebook is not a detailed explanation of 'how' distributions are dervied; rather 'why' we use different distributions.\n",
    "\n",
    "#### The Wikipedia definition of a probability distribution is as follows: \n",
    "#### <em> \" In probability theory and statistics, a probability distribution is a mathematical function that provides the probabilities of occurrence of different possible outcomes in an experiment. In more technical terms, the probability distribution is a description of a random phenomenon in terms of the probabilities of events. </em> \"\n",
    "\n",
    "## Formula-1 Example\n",
    "\n",
    "* Let us start with an extremely simple example, and work our way through different distributions. In the Formula 1, 2019 season, Ferraris' driver, Sebastian Vettel (Number 16), has not won a single race yet. As a Ferrari fan, this is extremely frustrating and dissapointing to see the 4-time world champion struggle to finish on podium (finishing in top 3 of a race).\n",
    "\n",
    "\n",
    "* During the Canadian Grand Prix, he finished first, then penalized with a 5 second penalty, for *blocking* the current world champion- Lewis Hamilton on track. With the penalty, he finished at second place. Of the 7 races till date in the 2019 championship, Vettel finished in 1st place just once (but never Won) Check this out: (https://wtf1.com/post/a-bullshit-penalty-for-vettel-handed-hamilton-the-canadian-gp-victory/).\n",
    "\n",
    "\n",
    "* My assumption (not according to any statistic), is that Sebastian will win once in every 7 races this season. Let us use the variable 'p', to describe probability of favourable scenario to occur. Hence, p = 1/7 in this case. There are 14 races to-go this season."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the chances that Sebastian will finish first in 'X' races this Season ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Lets start with the chances that Sebastian will win no race (not finish 1st in any of the remaining races). Remember, p = 1/7, q = 6/7, n = 14 (q - probability of faliure, n-number of races remaining in this season).\n",
    "* For him to lose in all the races, the WIN/ LOSE order should be as follows: L-L-L-L-L-L-L-L-L-L-L-L-L-L (14 losses in a row). The probability of this case occuring is (6/7) raised to the power 14. This can also be expressed as (1 - (1/7)) raised to the power 14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(6/7)**14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1-(1/7))**14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let us see the chance of him winning 7 of the 14 remaining races (Little too optimistic given how he's been performing). One combination could be him winning the next 7 races and losing 7, which would result in: <hr> W-W-W-W-W-W-W-L-L-L-L-L-L-L\n",
    "\n",
    "* Another could be him winning and losing alternative races, which is as follows. We observe in this case, that p, q, n, remain the same, just the combinations keep varying. <hr>  W-L-W-L-W-L-W-L-W-L-W-L-W-L \n",
    "\n",
    "* This can be solved by <strong> 14 <em>C</em> 7 </strong> (Combinations)* (1/7) <sup>7</sup> * (6/7) <sup>7</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3432*((1/7)**7)*((6/7)**7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above example seems highly unlikely to happen (Less than 0.14 % chance that Sebastian will win half the races). \n",
    "\n",
    "#### In this example, we have an event (of Sebastian winning or losing a race), and n=14 (14 races in total). Clearly, the values are discrete, and all the trials have the same chance of favourible/ unfavourible outcome. This problem is captured perfectly by: <hr>\n",
    "## I. Binomial Distribution \n",
    "\n",
    "* To find the Probability Mass Function of the distribution (not PDF), we use the following functions to get nCr. Now, we iterate through the number of the values the random variable can take.\n",
    "\n",
    "* We also know that p = 1/7, q = 6/7, n = 14.\n",
    "\n",
    "#### Hence, if we want to obtain the probability of k-sucessful trials of n-total trials, we use Binomial Distribution; and use the follwing to compute  Pmf <hr>\n",
    "$$Pmf: {\\binom {n}{k}}p^{k}(1-p)^{n-k}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE: https://stackoverflow.com/questions/4941753/is-there-a-math-ncr-function-in-python\n",
    "# Function to obtain nCr.\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import operator as op\n",
    "from functools import reduce\n",
    "\n",
    "def nCr(n, r):\n",
    "    r = min(r, n-r)\n",
    "    numer = reduce(op.mul, range(n, n-r, -1), 1)\n",
    "    denom = reduce(op.mul, range(1, r+1), 1)\n",
    "    return numer / denom\n",
    "\n",
    "def pltBinomialPmf(p, n):\n",
    "    q = 1-p\n",
    "    # new list for calculating pmf at different number of races.\n",
    "    pmf = []\n",
    "\n",
    "    # iterate over each race \n",
    "    for i in range(0,n):\n",
    "        pmf.append((nCr(n, i)*(p**i)*(q**(n-i))))\n",
    "    \n",
    "    plt.title(\"Probability Mass Function\")\n",
    "    plt.xlabel(\"Number of Races\")\n",
    "    plt.plot(np.arange(0,n), pmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltBinomialPmf(1/7,14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Just by number of individual/ independent trials (number of races in this case), and the favourible probability, we are able to estimate the probability of successfull/ unsuccessful events occuring.\n",
    "\n",
    "* Now, let us assume we have a new promising driver in Formula-1 fo next year, who won half the number of races in his Formula-2 career (will be a debutant in F1 next year, F2 this year). Let us assume he can win one race of every three races; the season is 21 races long. We have only two parameters to tweak.\n",
    "\n",
    "* We observe that the new rising star will most likely win 7 races (approximately). Also observe how this curve starts behaving like a Normal Distribution as p-> 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltBinomialPmf(1/3,21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaways: \n",
    "\n",
    "* When deciding which distribution best fits our data, understanding which domain our random ariable belongs to, is very important. Are the occurances discrete or continuous ? Does the occurance of events matter ? \n",
    "\n",
    "* Our data needs to be in discrete domain for us to use Binomial distribution. The order of events (successes or faliures) of individual Bernaulli trials does not matter. We are only concerned about the number of events (n), and the probability of them occuring (p), to model our problem. \n",
    "\n",
    "### Building up to Poisson Distribution\n",
    "\n",
    "* Previously, we saw only a discrete domain without time-intervals playing a part; what if we want to model our data for longer time duration ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the probability of 'X' crashes on any given day of the race weekend ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Previous numbers indicate that during every race weekend, there are 2 minor crashes and 1 major car crash which occurs at the venue (Including all practice laps, qualification laps, and the race itself). \n",
    "\n",
    "* We know that on average, there are 3 racing accidents/ incidents every race weekend. Let us set this average to λ. Hence, in our case, λ = 3 per race weekend.\n",
    "\n",
    "* The French Grand Prix is coming up next week, and the organizers want to improve driver safety + accident response times. However, they still need to know the chances of accidents; to best prepare themselves for the race weekend.\n",
    "\n",
    "* In both Question 1 and Question 2, we have the chance of success (Sebastian winning races, accidents occuring), both are <em> discrete </em> probability distributions, but have different domains (Question 1: Discrete domain, Question 2: Continuous domain). Hence, we use Poisson Distribution to model our problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Poisson Distribution\n",
    "\n",
    "#### The Pmf (Probability mass function) of Poisson distribution, is probability function, with 'k' number of events; with 'λ' - average number of events occuring within a continous time period.\n",
    "<hr>\n",
    "P(X=k) =   (λ<sup>k</sup> e<sup>-λ</sup>) / k! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Question asks for the probability of crashes per day, hence the rate needs to be converted from the unit 'weekend' to 'day'. The 'race weekend' consists of 4 full days. Hence, λ = 3/4 (number of crashes per day of the race weekend).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial(n):\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return n * factorial(n-1)\n",
    "\n",
    "def PoissonPmf(k, lambda_value):\n",
    "    return float(math.exp(-lambda_value)*(lambda_value**k))/factorial(k)\n",
    "\n",
    "def pltPoissonPmf(n, lambda_value):\n",
    "    pmf = []\n",
    "    for i in range(0,n):\n",
    "#         print(PoissonPmf(i, float(lambda_value)))\n",
    "        pmf.append(PoissonPmf(i, float(lambda_value)))\n",
    "    \n",
    "    plt.title(\"Probability Mass Function\")\n",
    "    plt.xlabel(\"Number of Racing Incidents\")\n",
    "    plt.plot(np.arange(0,n), pmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PoissonPmf(2,1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_value = 0.75\n",
    "\n",
    "pltPoissonPmf(10, lambda_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* With the above data, the orgnizers at the French Grand Prix can take decisions about staffing and safety personnel requirements during each race day.\n",
    "\n",
    "*Now, let us assume λ = 3 (3 crashes per day, for all days of the race weekend)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_value = 3\n",
    "\n",
    "pltPoissonPmf(10, lambda_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do both questions/ two distributions relate to each other ?  (Similarities, Differences) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_distribution_details = pd.DataFrame()\n",
    "df_distribution_details['Distribution Name'] = ['Binomial', 'Poisson']\n",
    "df_distribution_details['Type'] = ['Discrete', 'Discrete']\n",
    "df_distribution_details['Parameters'] = ['n, p: [0,1],(# of events),(% success),', 'λ > 0 (Event Rate)']\n",
    "df_distribution_details['Mean'] = ['np','λ']\n",
    "df_distribution_details['Variance'] = ['np (1 - p)','λ']\n",
    "\n",
    "\n",
    "df_distribution_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaways:\n",
    "\n",
    "\n",
    "\n",
    "* In both distributions, the events occuring are n-individual Bernaulli trials, hence, are each trial has no effect on the next trial.\n",
    "\n",
    "* As the number of samples 'n' in Binomial distribution increase, and the success probability 'p' decreases, we do not need two parameters to model (n, p); λ (Rate parameter) is enough to generate a reliable model. \n",
    "\n",
    "##### SOURCE: http://www.oxfordmathcenter.com/drupal7/node/297\n",
    "\n",
    "* Hence, the Binomial and Poisson distributions are extremely similar in nature, both of them can be used to model data when the order of successes/ faliures does not matter, the only difference being discrete occurances over discrete time domain (Binomial) and disrete occurances in fixed interval of time (Poisson). \n",
    "\n",
    "* What if the order mattered ? In many day to day scenarios, order does matter ! That's where Negative Binomial distribution comes into picture; and Geometric distribution is a special case of Negative Binomial distribution.\n",
    "\n",
    "<hr>\n",
    "\n",
    "## How many driver meetings should I attend before I can get a picture with 1 driver ? <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fans get to meet and interact with Formula 1 drivers during race weekends in the driver meetings. The chances of not getting a picture with a driver is 7 out of 8 (Getting autographs is easy; getting pictures is hard). Hence, the success probability (p) = 1/8.\n",
    "\n",
    "* Lets first try to figure out the chance of getting a picture on my very first attempt. We know, p = 1/8. As the number of trials is just 1, the chance of getting a picture on first try is 1/8.\n",
    "\n",
    "* Lets now see the probability of getting a picture on 2nd trial. Remember, for this case to happen, I should not be able to get a picture with the first driver.<hr> 1st attempt: No picture, 2nd attemp: Successful "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The chance for this case is (7/8)*(1/8)\n",
    "(7/8)*(1/8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now, lets see the probability of getting a picture on the third attempt; first two attempts were faliure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The chance for this case is (7/8)*(7/8)*(1/8)\n",
    "(7/8)*(7/8)*(1/8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, lets consider other variations of the same question. \n",
    "### What are the chances I will get a picture in the first three attempts ? \n",
    "\n",
    "*  The answer is: P(X<=3) = P(X=1) + P(X=2) + P(X=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(X=1) = (1/8)\n",
    "# P(X=2) = (7/8)*(1/8)\n",
    "# P(X=3) = (7/8)*(7/8)*(1/8)\n",
    "\n",
    "(1/8) + (7/8)*(1/8) + (7/8)*(7/8)*(1/8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As you can see, this can be generalized by the following Pmf (Yes, not Pdf, as the distribution is still discrete).  Pmf of Geometric Distribution with success probability p<br> \n",
    "\n",
    "## III. Geometric Distribution \n",
    "\n",
    "$$Pr(X=k)=(1-p)^{k-1}p$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On average, how many drivers do I need to visit to get a picture ?\n",
    "\n",
    "$${{ E(X) = 1/p = 1/0.125 = 8}}$$\n",
    "*  We need to visit 8 drivers on average, before we can get a picture with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pmf function for geometric distribution\n",
    "\n",
    "def GeometricPmf(p, i):\n",
    "    return ((1-p)**(i-1))*(p)\n",
    "\n",
    "def pltGeometricPmf(p, n):\n",
    "    pmf = []\n",
    "    for i in range(0,n):\n",
    "        pmf.append(GeometricPmf(p, i))\n",
    "    \n",
    "    plt.title(\"Probability Mass Function\")\n",
    "    plt.xlabel(\"Number of Drivers\")\n",
    "    plt.plot(np.arange(0,n), pmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltGeometricPmf(0.125, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distribution_details_update1 = pd.DataFrame([['Geometric','Discrete',\n",
    "                                            'p: [0,1], (% success)','1/p','(1-p)/p**2']],\n",
    "                                               columns=df_distribution_details.columns.tolist(),\n",
    "                                            )\n",
    "\n",
    "df_distribution_details = pd.concat([df_distribution_details, \n",
    "                                     df_distribution_details_update1]).reset_index(drop=True)\n",
    "\n",
    "df_distribution_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Special access passes to the Formula 1 race weekends grants time for kids to interact with the drivers. Each kid gets to spend around 10 minutes with any of the 20 drivers on the grid.  \n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "* Remember, when the order of outcome matters, use Geometric distribution (waiting for first success, with all faliures before).\n",
    "\n",
    "* However, when the domain is continuous and we need to understand the time elapsed between two events ? That's where exponential distribution comes into the picture.\n",
    "\n",
    "<hr>\n",
    "\n",
    "##  IV. Exponential Distribution \n",
    "\n",
    "## What is the chance that a kid gets to meet Sebastian for 10-15 minutes ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For this sort of question, where we need to find probability of events in continous domain, we use Exponential distribution. \n",
    "\n",
    "*  We know that the average time a driver spends with a kid is 10 minutes. We use λ, which is inverse of mean. Hence, λ = 1/10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Pdf of Exponential Distribution is<br> \n",
    "P(X=x) = λe<sup>-λx</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pdf function for exponential distribution\n",
    "\n",
    "def ExponentialPdf(lambda_value, i):\n",
    "    return (lambda_value*(math.exp(-lambda_value*i)))\n",
    "\n",
    "def pltExponentialPdf(lambda_value, n):\n",
    "    pdf = []\n",
    "    for i in range(0,n):\n",
    "        pdf.append(ExponentialPdf(lambda_value, i))\n",
    "    \n",
    "    plt.title(\"Probability Density Function\")\n",
    "    plt.xlabel(\"Number of Minutes\")\n",
    "    plt.plot(np.arange(0,n), pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltExponentialPdf(0.1, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To answer the above question, i.e., the chance to meet Sebastian for 10-15 minutes, can be found using the following:\n",
    "\n",
    "#### P(10<X<15) = P(X<15) - P(X<10) = Difference of CDF till 15th minute - CDF till 10th minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_value = 0.1\n",
    "\n",
    "P_10_15 = (1-math.exp(-lambda_value*15)) - (1-math.exp(-lambda_value*10))\n",
    "P_10_15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hence, there is 15 % chance that the kid will spend 10-15 minutes with the driver. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distribution_details_update2 = pd.DataFrame([['Exponential','Continuous',\n",
    "                                            'λ','1/λ','λ**-2']],\n",
    "                                               columns=df_distribution_details.columns.tolist(),\n",
    "                                            )\n",
    "\n",
    "df_distribution_details = pd.concat([df_distribution_details, \n",
    "                                     df_distribution_details_update2]).reset_index(drop=True)\n",
    "\n",
    "df_distribution_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequentist vs Bayesian Thinking with MLE & MAP\n",
    "\n",
    "* Now, lets us explore what MLE and MAP stand for, and how they derive as basis for solving probabilistic/ statistical parameter estimation for all distributions, and how these concepts can further be extrapolated to form basis for Probabilistic Classifiers.\n",
    "\n",
    "\n",
    "* We also take a look at Frequentist and Bayesian Approach towards learning/ estimating parameters to model real wold data.\n",
    "\n",
    "<hr> \n",
    "\n",
    "## Frequentist Framework\n",
    "\n",
    "## Bernoulli Process:\n",
    "\n",
    "* Let us start off with the n-Bernoulli trials, with chance of 'p', as number of Bernoulli trials increase over time. As we know, we can sample a single Bernoulli trial by setting n=1 in a Binomial distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_1 = np.random.binomial(p=0.3, n=1)\n",
    "\n",
    "trial_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now, we sample 100,000 points from the same distribution, to understand our distribution. Remember, Frequentist approach towards a problem is by repeating the same experiment over and over. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100000 independent Bernoulli trials\n",
    "\n",
    "trails_n = [np.random.binomial(p=0.3, n=1) for i in range(0,100000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plot\n",
    "\n",
    "sns.distplot(trails_n, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequencies of either class 0 or 1.\n",
    "\n",
    "frequencies = pd.DataFrame(trails_n, columns=['n']).n.value_counts()\n",
    "\n",
    "count_y0, count_y1 = frequencies[0], frequencies[1]\n",
    "\n",
    "# class label\n",
    "y0, y1 = 0, 1\n",
    "\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate of Maximum Likelihood is\n",
    "\n",
    "p = (y0*count_y0 + y1*count_y1)/(count_y0 + count_y1)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The frequentist approach here is that after n-number of samples, we try to predict the parameter such that it fits the data-well. Essentially, we want to estimate parameters which best 'fit' our data.\n",
    "\n",
    "\n",
    "* In this case, we are not thinking of a 'prior', and just use the data well to figure out the parameter.\n",
    "\n",
    "## Binomial Distribution, pmf and MLE\n",
    "\n",
    "Suppose we have n-independent Bernoulli trials, each having the probability 'p' of class 1. Let 'k' be the number of successes in trials, then, the Pmf of Binomial distribution is as follows: \n",
    "\n",
    "$$Pmf: {\\binom {n}{k}}p^{k}(1-p)^{n-k}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE: https://stackoverflow.com/questions/4941753/is-there-a-math-ncr-function-in-python\n",
    "# Function to obtain nCr.\n",
    "\n",
    "import operator as op\n",
    "from functools import reduce\n",
    "\n",
    "def nCr(n, r):\n",
    "    r = min(r, n-r)\n",
    "    numer = reduce(op.mul, range(n, n-r, -1), 1)\n",
    "    denom = reduce(op.mul, range(1, r+1), 1)\n",
    "    return numer / denom\n",
    "\n",
    "def pltBinomialPmf(p, n):\n",
    "    q = 1-p\n",
    "    # new list for calculating pmf at different number of races.\n",
    "    pmf = []\n",
    "\n",
    "    # iterate over each race \n",
    "    for i in range(0,n):\n",
    "        pmf.append((nCr(n, i)*(p**i)*(q**(n-i))))\n",
    "    \n",
    "    plt.title(\"Probability Mass Function\")\n",
    "    plt.xlabel(\"Number of Trials\")\n",
    "    plt.plot(np.arange(0,n), pmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltBinomialPmf(0.3, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above equation for Pmf: ${\\binom {n}{k}}p^{k}(1-p)^{n-k}$, we can estimate the MLE (Maximum Likelihood Estimate)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: https://www.projectrhea.org/rhea/index.php/MLE_Examples:_Binomial_and_Poisson_Distributions_OldKiwi\n",
    "\n",
    "<img src=\"bayes1.png\" width=\"400\">\n",
    "\n",
    "Hence, the frequentist approach is essentially the average number of times a value occurs, across all trials. Remember, there is no prior information here, to estimate/ include in our model.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Framework\n",
    "\n",
    "* We as humans start with some prior knowledge to infer or draw conclusions. Over time, the 'priors' may change, and with more evidence, tend to believe posterior probability more.\n",
    "\n",
    "\n",
    "* Say we toss a coin twice and both end up being heads (Heads, Heads); from a Frequentists perspective, the chance of tails occuring is 0; and assumes that the next coin toss will result in heads.\n",
    "\n",
    "\n",
    "* However, we do have prior knowledge, that eventually over time (in terms of sample size), the chance of getting heads will eventually fall at 0.5 for an unbiased coin. How do we know this ? Well, thats called the 'prior'.\n",
    "\n",
    "\n",
    "* From MLE, we know try to figure out the point estmate of ${\\theta}$, where \n",
    "\n",
    "$${\\theta MLE} = arg max {P(D/\\theta)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For MAP, or the posterior probability which includes a 'prior' belief, \n",
    "\n",
    "$${\\theta MAP} = arg max   {P(\\theta/D)} = \\dfrac {likelihood * prior}  {evidence}$$\n",
    "\n",
    "### Conjugate Prior\n",
    "\n",
    "* To estimate MAP, we already have the ${P(D/\\theta)}$ (likelihood), and need to introduce a prior into the equation. We introduce a prior distribution for ${\\theta}$,\n",
    "where $${\\theta} ∼ {Beta(\\alpha, \\beta)}$$\n",
    "\n",
    "\n",
    "* We choose a Beta distribution for prior given the fact that out likelihood function is a Bernoulli distribution. (For coin toss example above). Using Beta prior will also turn the posterior into a Beta distribution as they are Conjugate pairs.\n",
    "\n",
    "\n",
    "$${P(\\theta/D)} ∝ {P(D/\\theta)} P(\\theta) $$\n",
    "\n",
    "$${P(\\theta/D)} ∝ {\\theta^{x} (1-\\theta)^{1-x}}{\\theta^{\\alpha-1}}({1-\\theta})^{\\beta-1}$$\n",
    "\n",
    "$${P(\\theta/D)} ∝ {\\theta^{\\alpha + x - 1} (1-\\theta)^{\\beta - x}}$$\n",
    "\n",
    "$$Hence, {P(\\theta/D)} ∼ Beta(\\alpha + x, \\beta + n - x)$$\n",
    "\n",
    "## Sanity Check\n",
    "\n",
    "* ${\\alpha}$ and ${\\beta}$ in a Beta distribution are the two parameters where ${\\alpha}$, ${\\beta}$ > 0. Directly using our coin toss example, we have some prior distribution Beta(${\\alpha}, {\\beta}$), where ${\\alpha}$ are number of successes (heads) and ${\\beta}$ is the number of failures (tails).\n",
    "\n",
    "\n",
    "* Together, they constitute the sample size (n). Let us assume we know from some prior distribution, where number of success is 4 and number of faliures is 4. Below is how the Beta distribution looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import beta\n",
    "\n",
    "alpha_param = beta_param = 4\n",
    "x = np.arange (0.01, 1, 0.01)\n",
    "y = beta.pdf(x, alpha_param, beta_param)\n",
    "plt.plot(x,y)\n",
    "plt.title('Prior Beta Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We see that the mean is on ${\\dfrac \\alpha  {\\alpha + \\beta}}$, Hence, the mean of prior distribution is 0.5.\n",
    "\n",
    "\n",
    "* Now, as per our ase, we had two heads in a row. hence, X = 2, N = 2; Now let us use prior information along with likelihood to calculate posterior probability (MAP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import beta\n",
    "\n",
    "def plotBetaDist(a, b, x_param, n_param):\n",
    "    x = np.arange (0.01, 1, 0.01)\n",
    "    y = beta.pdf(x,a+x_param,b+n_param-x_param)\n",
    "    plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = 2, N = 2\n",
    "\n",
    "plotBetaDist(4, 4, x_param=2, n_param=2)\n",
    "plt.title('Posterior Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We observe that the MAP is at around 0.6 (close to actual probability of coin toss for heads or tails). However, according to the frequentist approach, the probability of tails was 0 (Which is not true). Hence, using the MAP estimate is a predictor approach in this case.\n",
    "\n",
    "\n",
    "* As the number of samples increase (N), the effect of both ${\\alpha, \\beta}$ reduce, and there is a shift in importance from prior to likelihood.\n",
    "\n",
    "\n",
    "* For example, let us say we assume the same distribution as above, with number of successes and faliures (heads and tails) is 4 each. Hence, below is the prior Beta distribution plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_param = beta_param = 4\n",
    "x = np.arange (0.01, 1, 0.01)\n",
    "y = beta.pdf(x, alpha_param, beta_param)\n",
    "plt.plot(x,y)\n",
    "plt.title('Prior Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let us assume we tossed a new coin 100 times, and turns out heads appears 30 times (X=30, N=100). Hence, the posterior Beta distribution is as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = 30, N = 100\n",
    "\n",
    "plotBetaDist(4, 4, x_param=30, n_param=100)\n",
    "plt.title('Posterior Distribution: Biased Coin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As you see, the probability of heads occuring is around 0.3 (Even though we started with equal priors). As the sample size increases, the power of prior distribution decreases, and we can conclude that the coin is biased. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
